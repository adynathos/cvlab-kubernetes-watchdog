{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from kubernetes_asyncio import client, config\n",
    "import kubernetes_asyncio as kube\n",
    "import asyncio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bedn bedn2 benlalahpod.com katircio-imagenet katircio-imagenet2 katircio-localiz kicirogl-airsim-2 lis-image-test mv-cvpr3 nakka-advseg11 nakka-advseg14 nakka-advseg20 nsd oner-rt-fulldata-40 oner-rt-fulldata-40-2 rbermude-multiflow remelli-mvp s2t1-ud-l-1 sguo-pytorch-imagenet-iclr weliu-cvpr wickrama-experiments-1 wickrama-experiments-2 wickrama-experiments-3 wickrama-experiments-4 wickrama-experiments-5 wwang-imagenet0 wwang-imagenet1 wwang-imagenet2\n"
     ]
    }
   ],
   "source": [
    "async def list_pods_once():\n",
    "\tawait kube.config.load_kube_config()\n",
    "\tapi = kube.client.CoreV1Api()\n",
    "\t\n",
    "\tpod_list_response = await api.list_namespaced_pod('cvlab')\n",
    "\t\n",
    "\tprint(' '.join(f'{pod.metadata.name}' for pod in pod_list_response.items))\n",
    "\t\n",
    "\treturn pod_list_response\n",
    "\t\n",
    "# asyncio.run(main())\n",
    "pod_list = await list_pods_once()\n",
    "\n",
    "# Configs can be set in Configuration class directly or using helper\n",
    "# utility. If no argument provided, the config will be loaded from\n",
    "# default location.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing on pod [bedn]\n"
     ]
    }
   ],
   "source": [
    "pod_to_test = pod_list.items[0]\n",
    "print(f'Testing on pod [{pod_to_test.metadata.name}]')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GPU status with nvidia-smi\n",
    "\n",
    "Example queries: <https://nvidia.custhelp.com/app/answers/detail/a_id/3751/~/useful-nvidia-smi-queries>  \n",
    "List of fields: <https://briot-jerome.developpez.com/fichiers/blog/nvidia-smi/list.txt>\n",
    "\n",
    "`nvidia-smi --format=csv --loop=2 --query-gpu=index,utilization.gpu,utilization.memory,memory.used,memory.total`\n",
    "\n",
    "Injections:  \n",
    "`kubectl exec -it container -- /usr/bin/nvidia-smi --format=csv --loop=2 --query-gpu=index,utilization.gpu,utilization.memory,memory.used,memory.total`\n",
    "\n",
    "Run command for 10s:  \n",
    "`timeout 10 something`  \n",
    "`timeout 30 nvidia-smi --format=csv --loop=3 --query-gpu=index,utilization.gpu,utilization.memory,memory.used,memory.total`  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[0;31mSignature:\u001b[0m \u001b[0mapi\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconnect_get_namespaced_pod_exec\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnamespace\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
       "\u001b[0;31mDocstring:\u001b[0m\n",
       "connect_get_namespaced_pod_exec  # noqa: E501\n",
       "\n",
       "connect GET requests to exec of Pod  # noqa: E501\n",
       "This method makes a synchronous HTTP request by default. To make an\n",
       "asynchronous HTTP request, please pass async_req=True\n",
       ">>> thread = api.connect_get_namespaced_pod_exec(name, namespace, async_req=True)\n",
       ">>> result = thread.get()\n",
       "\n",
       ":param async_req bool\n",
       ":param str name: name of the PodExecOptions (required)\n",
       ":param str namespace: object name and auth scope, such as for teams and projects (required)\n",
       ":param str command: Command is the remote command to execute. argv array. Not executed within a shell.\n",
       ":param str container: Container in which to execute the command. Defaults to only container if there is only one container in the pod.\n",
       ":param bool stderr: Redirect the standard error stream of the pod for this call. Defaults to true.\n",
       ":param bool stdin: Redirect the standard input stream of the pod for this call. Defaults to false.\n",
       ":param bool stdout: Redirect the standard output stream of the pod for this call. Defaults to true.\n",
       ":param bool tty: TTY if true indicates that a tty will be allocated for the exec call. Defaults to false.\n",
       ":return: str\n",
       "         If the method is called asynchronously,\n",
       "         returns the request thread.\n",
       "\u001b[0;31mFile:\u001b[0m      ~/Programs/conda/lib/python3.7/site-packages/kubernetes_asyncio/client/api/core_v1_api.py\n",
       "\u001b[0;31mType:\u001b[0m      method\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "api = kube.client.CoreV1Api()\n",
    "api.connect_get_namespaced_pod_exec?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Executing inside a container\n",
    "\n",
    "Example: <https://github.com/tomplus/kubernetes_asyncio/blob/master/examples/example3.py>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['/usr/bin/timeout', '5', '/usr/bin/nvidia-smi', '--format=csv', '--loop=1', '--query-gpu=index,utilization.gpu,utilization.memory,memory.used,memory.total']\n",
      "Req <coroutine object ApiClient.__call_api at 0x7fb36727a5f0>\n",
      "Query response:  index, utilization.gpu [%], utilization.memory [%], memory.used [MiB], memory.total [MiB]\n",
      "0, 0 %, 0 %, 8932 MiB, 32510 MiB\n",
      "1, 0 %, 0 %, 8924 MiB, 32510 MiB\n",
      "0, 87 %, 18 %, 8932 MiB, 32510 MiB\n",
      "1, 31 %, 1 %, 8924 MiB, 32510 MiB\n",
      "0, 95 %, 33 %, 8932 MiB, 32510 MiB\n",
      "1, 84 %, 27 %, 8924 MiB, 32510 MiB\n",
      "0, 88 %, 29 %, 8932 MiB, 32510 MiB\n",
      "1, 41 %, 23 %, 8924 MiB, 32510 MiB\n",
      "0, 0 %, 0 %, 8932 MiB, 32510 MiB\n",
      "1, 0 %, 0 %, 8924 MiB, 32510 MiB\n",
      "\n"
     ]
    }
   ],
   "source": [
    "GPU_QUERY_FIELDS = [\n",
    "\t'index',\n",
    "\t'utilization.gpu',\n",
    "\t'utilization.memory',\n",
    "\t'memory.used',\n",
    "\t'memory.total',\n",
    "]\n",
    "GPU_QUERY_CMD = [\n",
    "\t'/usr/bin/timeout', '5',\n",
    "\t'/usr/bin/nvidia-smi',\n",
    "\t'--format=csv',\n",
    "  \t'--loop=1',\n",
    "\tf'--query-gpu={\",\".join(GPU_QUERY_FIELDS)}',\n",
    "]\n",
    "print(GPU_QUERY_CMD)\n",
    "\n",
    "async def query_gpu_status():\n",
    "\tawait kube.config.load_kube_config()\n",
    "\tapi_ws = kube.client.CoreV1Api(api_client=kube.stream.WsApiClient())\n",
    "# \tapi_ws = kube.client.CoreV1Api()\n",
    "\n",
    "\tcmd = GPU_QUERY_CMD\n",
    "\tname = 'sguo-pytorch-imagenet-iclr'\n",
    "# \tname = 'wwang-imagenet2'\n",
    "\tnamespace = 'cvlab'\n",
    "\t\n",
    "# \tcmd = ['ls']\n",
    "\t\n",
    "\treq = api_ws.connect_get_namespaced_pod_exec(\n",
    "\t\tname = name, \n",
    "\t\tnamespace = namespace,\n",
    "\t\tcommand = cmd,\n",
    "\t\tstderr=True,\n",
    "\t\tstdin=False,\n",
    "\t\tstdout=True,\n",
    "\t\ttty=False,\n",
    "\n",
    "# \t\tasync_req=True,\n",
    "# \t\t_preload_content=False,\n",
    "\t)\n",
    "\t\n",
    "\tprint('Req', req)\n",
    "\tresponse = await req\n",
    "\tprint(\"Query response: \", response)\n",
    "\treturn response\n",
    "\t\n",
    "# \tw = kube.watch.Watch()\n",
    "\t\n",
    "# \tasync for event in w.stream(api_ws.connect_get_namespaced_pod_exec,\n",
    "# \t\tname = name, \n",
    "# \t\tnamespace = namespace,\n",
    "# \t\tcommand = cmd,\n",
    "# \t\tstderr=True,\n",
    "# \t\tstdin=False,\n",
    "# \t\tstdout=True,\n",
    "# \t\ttty=False,\n",
    "\t\t\t\t\t\t\t\t\n",
    "# \t\tasync_req=True,\n",
    "# \t\t_preload_content=False,\n",
    "# \t):\n",
    "# \t\tprint(event)\n",
    "\t\n",
    "\n",
    "# \treturn response\n",
    "\n",
    "r = await query_gpu_status()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "invalid literal for int() with base 10: '' in []\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'index': 0,\n",
       "  'utilization.gpu': 0.0,\n",
       "  'utilization.memory': 0.0,\n",
       "  'memory.used': 8932.0,\n",
       "  'memory.total': 32510.0},\n",
       " {'index': 1,\n",
       "  'utilization.gpu': 0.0,\n",
       "  'utilization.memory': 0.0,\n",
       "  'memory.used': 8924.0,\n",
       "  'memory.total': 32510.0},\n",
       " {'index': 0,\n",
       "  'utilization.gpu': 0.87,\n",
       "  'utilization.memory': 0.18,\n",
       "  'memory.used': 8932.0,\n",
       "  'memory.total': 32510.0},\n",
       " {'index': 1,\n",
       "  'utilization.gpu': 0.31,\n",
       "  'utilization.memory': 0.01,\n",
       "  'memory.used': 8924.0,\n",
       "  'memory.total': 32510.0},\n",
       " {'index': 0,\n",
       "  'utilization.gpu': 0.9500000000000001,\n",
       "  'utilization.memory': 0.33,\n",
       "  'memory.used': 8932.0,\n",
       "  'memory.total': 32510.0},\n",
       " {'index': 1,\n",
       "  'utilization.gpu': 0.84,\n",
       "  'utilization.memory': 0.27,\n",
       "  'memory.used': 8924.0,\n",
       "  'memory.total': 32510.0},\n",
       " {'index': 0,\n",
       "  'utilization.gpu': 0.88,\n",
       "  'utilization.memory': 0.29,\n",
       "  'memory.used': 8932.0,\n",
       "  'memory.total': 32510.0},\n",
       " {'index': 1,\n",
       "  'utilization.gpu': 0.41000000000000003,\n",
       "  'utilization.memory': 0.23,\n",
       "  'memory.used': 8924.0,\n",
       "  'memory.total': 32510.0},\n",
       " {'index': 0,\n",
       "  'utilization.gpu': 0.0,\n",
       "  'utilization.memory': 0.0,\n",
       "  'memory.used': 8932.0,\n",
       "  'memory.total': 32510.0},\n",
       " {'index': 1,\n",
       "  'utilization.gpu': 0.0,\n",
       "  'utilization.memory': 0.0,\n",
       "  'memory.used': 8924.0,\n",
       "  'memory.total': 32510.0},\n",
       " None]"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "def process_row_id(val):\n",
    "\treturn int(val)\n",
    "\n",
    "def process_row_percent(val):\n",
    "\treturn float(val.split(maxsplit=1)[0]) * 0.01\n",
    "\n",
    "def process_row_mem(val):\n",
    "\treturn float(val.split(maxsplit=1)[0])\n",
    "\n",
    "GPU_QUERY_PROCESSORS = {\n",
    "\t'index': int,\n",
    "\t'utilization.gpu': process_row_percent,\n",
    "\t'utilization.memory': process_row_percent,\n",
    "\t'memory.used': process_row_mem,\n",
    "\t'memory.total': process_row_mem,\n",
    "}\n",
    "\n",
    "\n",
    "def process_nvidiasmi_line(report_line):\n",
    "\ttry:\n",
    "\t\treturn {\n",
    "\t\t\tfield: GPU_QUERY_PROCESSORS[field](value.strip())\n",
    "\t\t\tfor field, value in zip(GPU_QUERY_FIELDS, report_line.split(','))\n",
    "\t\t}\n",
    "\texcept Exception as e:\n",
    "\t\tprint(f'{e} in [{report_line}]')\n",
    "\n",
    "def process_nvidiasmi_report(report_str):\n",
    "\t\n",
    "\treport_lines = report_str.split('\\n')\n",
    "\t\n",
    "\treport_data = [\n",
    "\t\tprocess_nvidiasmi_line(line) for line in report_lines[1:]\n",
    "\t]\n",
    "\t\n",
    "\treturn report_data\n",
    "\t\n",
    "process_nvidiasmi_report(r)\n",
    "\t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "loadtxt() got an unexpected keyword argument 'names'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-27-ce02668939ff>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mio\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mStringIO\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloadtxt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mStringIO\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mskiprows\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdelimiter\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m','\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnames\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mGPU_QUERY_FIELDS\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconverters\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreplace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'.'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m''\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mGPU_QUERY_PROCESSORS\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m: loadtxt() got an unexpected keyword argument 'names'"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from io import StringIO\n",
    "np.loadtxt(StringIO(r), skiprows=1, delimiter=',', names=GPU_QUERY_FIELDS, converters={k.replace('.', ''): v for k, v in GPU_QUERY_PROCESSORS.items()})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "res_parsed = np.genfromtxt(\n",
    "\tStringIO(r), \n",
    "\tdelimiter = ',', \n",
    "\tautostrip = True,\n",
    "\tdtype=None, # precent casting to float\n",
    " \tnames=GPU_QUERY_FIELDS,\n",
    " \tskip_header = 1, \n",
    "# \tnames=True,\n",
    "\tdeletechars = '', # prevent mangling of names\n",
    "\tconverters = GPU_QUERY_PROCESSORS,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([(0, 0.  , 0.  , 8932., 32510.), (1, 0.  , 0.  , 8924., 32510.),\n",
       "       (0, 0.87, 0.18, 8932., 32510.), (1, 0.31, 0.01, 8924., 32510.),\n",
       "       (0, 0.95, 0.33, 8932., 32510.), (1, 0.84, 0.27, 8924., 32510.),\n",
       "       (0, 0.88, 0.29, 8932., 32510.), (1, 0.41, 0.23, 8924., 32510.),\n",
       "       (0, 0.  , 0.  , 8932., 32510.), (1, 0.  , 0.  , 8924., 32510.)],\n",
       "      dtype=[('index', '<i4'), ('utilization.gpu', '<f8'), ('utilization.memory', '<f8'), ('memory.used', '<f8'), ('memory.total', '<f8')])"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res_parsed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.27474623, 0.27450015, 0.27474623, 0.27450015, 0.27474623,\n",
       "       0.27450015, 0.27474623, 0.27450015, 0.27474623, 0.27450015])"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mem_relative = res_parsed['memory.used'] / res_parsed['memory.total']\n",
    "mem_relative"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
